本研究提出一個結合深度強化學習的多細緻度模擬最佳化方法對動態的機器人智動揀貨系統(Robotic Mobile Fulfillment System, RMFS) 對料架順序指派與料架重新定位的組合最佳化問題進行建模並分析。RMFS系統是一種由中央系統控制包括機器人、料架以及揀貨站等組件，確定規則指派料架並由移動機器人依據特定順序搬運至揀貨站，降低揀選員在料架與揀選站之間的移動距離，提高倉儲系統的揀選效率。在過往研究中為了縮短解決方案的求解時間，多在靜態的環境下設計最佳化演算法，但此環境所求出的解決方案因忽略過多的環境因素，無法在高度動態的環境下使用，為了更貼近實務，也有許多學者應用模擬的方法來求解最佳的解決方案，但每次模擬需耗費大量的計算資源。因此，本研究設計多細緻度模擬最佳化(Multifidelity Optimization with Ordinal Transformation and Optimal Sampling, MO^2  TOS)的模擬框架，透過建立出低細緻度與高細緻度兩種模型，再縮短求解時間的同時提升解決方案的準確度。低細緻度模型通過忽略環境與機器人之間的影響，快速尋找出高品質或具備潛力的備選方案; 而在高細緻度模型中則考慮實務環境下多台機器人之間的壅塞與碰撞等問題，來對解決方案進行模擬，提升準確性。且在過往研究中當料架完成揀選任務時回到儲存區存放所應用的重新定位策略通常僅應用固定規則或不進行重新定位，來降低系統的負擔，但在沒有考量未來訂單需求的狀態下，這樣的策略可能導致鄰近工作站的儲存空間頻繁發生雍塞、碰撞與繞路問題。本研究更進一步地提出在高細緻度模擬的過程中引入深度強化學習(Deep Reinforcement Learning, DRL)，通過設計多維度的狀態空間與獎勵使代理人可以通過與環境的互動，學習出最適合的重新定位策略，降低壅塞、碰撞與繞路問題。最後，利用多個資料集進行實驗分析，驗證提出之方法的有效性與發展潛力。
This study proposes a framework that integrates multi-fidelity simulation optimiza-tion (MFSO) with deep reinforcement learning (DRL) to solve the pod sequencing and repositioning problem (PSRP) in a Robotic Mobile Fulfillment System (RMFS). RMFS is widely used in modern warehouses and distribution centers to optimize order fulfill-ment by allowing robots to transport pods directly to pickers, enhancing efficiency and reducing manual labor. Previous studies have focused on developing optimization algo-rithms under static assumptions to reduce computational time. Conventional optimiza-tion methods based on static models often fail to capture the complexities of real-world warehouse operations, where dynamic interactions among robots, racks, and orders are pervasive. To bridge this gap, simulation-based optimization has gained prominence for its ability to model realistic warehouse behavior. However, high-fidelity simulations while accurate are computationally intensive, limiting their practical scalability. This study proposes a multi-fidelity simulation optimization framework that combines low-fidelity and high-fidelity models to balance solution quality and computational efficien-cy. The low-fidelity model abstracts away robot-level interactions to rapidly explore the solution space and identify promising candidates, which are then refined through high-fidelity simulations that account for congestion, collision, and other operational con-straints. Beyond sequencing optimization, repositioning strategies for completed racks are typically rule-based or entirely omitted to simplify system logic. Yet, such simplifica-tions often fail in high-density or high-demand zones, leading to avoidable congestion and suboptimal throughput especially when future order demand is disregarded. To ad-dress this, the proposed framework integrates DRL into the high-fidelity simulation pro-cess. A carefully designed multi-dimensional state space and reward structure enables the DRL agent to learn adaptive repositioning policies through real-time environmental interaction, thereby reducing operational bottlenecks and improving system resilience. Extensive experimental evaluations across a range of datasets demonstrate that the pro-posed method significantly enhances both solution quality and computational efficiency. These findings highlight the method’s robustness and scalability, affirming its practical value for intelligent decision-making in dynamic RMFS.
